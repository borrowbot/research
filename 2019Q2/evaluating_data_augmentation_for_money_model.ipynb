{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pathos.multiprocessing as mp\n",
    "\n",
    "from simple_state_recurrent_model.model import SimpleRecurrentModel\n",
    "from simple_state_recurrent_model.evaluation import Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/Users/frankwang/projects/data_model_repo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for f in os.listdir(os.path.join(DATA_DIR, 'datasets/money_detection/')):\n",
    "    with open(os.path.join('datasets/money_detection/', f), 'r') as fopen:\n",
    "        data += yaml.load(fopen)\n",
    "input_data = [d['input'] for d in data]\n",
    "label_data = [d['labels'] for d in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Augmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Augmentor(object):\n",
    "    def __init__(self, input_data, label_data):\n",
    "        self.input_data = input_data\n",
    "        self.label_data = label_data\n",
    "        \n",
    "        self.labels = []\n",
    "        for i, s in enumerate(self.input_data):\n",
    "            for label in self.label_data[i]:\n",
    "                self.labels.append(s[label[0]:label[1]])\n",
    "                \n",
    "        self.aug_input_data = []\n",
    "        self.aug_label_data = []\n",
    "                \n",
    "    def substitute(self, input_string, labels):\n",
    "        new_entries = random.choices(self.labels, k=len(labels))\n",
    "        end_idx = 0\n",
    "        ret_s = ''\n",
    "        ret_l = []\n",
    "        \n",
    "        for i, lab in enumerate(labels):\n",
    "            ret_s += input_string[end_idx:lab[0]]\n",
    "            ret_s += new_entries[i]\n",
    "            ret_l.append([len(ret_s) - len(new_entries[i]), len(ret_s)])\n",
    "            end_idx = lab[1]\n",
    "            \n",
    "        ret_s += input_string[end_idx:]\n",
    "        return ret_s, ret_l\n",
    "    \n",
    "    def generate_aug_data(self, n):\n",
    "        for inp, lab in zip(self.input_data, self.label_data):\n",
    "            for _ in range(n):\n",
    "                new_inp, new_lab = self.substitute(inp, lab)\n",
    "                self.aug_input_data.append(new_inp)\n",
    "                self.aug_label_data.append(new_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = Augmentor(input_data, label_data)\n",
    "a.generate_aug_data(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Overwriting the loo_cross_validation to do data augmentation as part of training\n",
    "\n",
    "def loo_cross_validation(self, batch_size=32, train_rate=0.1, steps=1, epochs_per_step=100000, threads=4):\n",
    "    def loo_x_validate(loo_cand):\n",
    "        model = SimpleRecurrentModel(**self.model_args)\n",
    "        filtered_inputs = [self.input_data[i] for i in range(len(self.input_data)) if i != loo_cand]\n",
    "        filtered_targets = [self.target_data[i] for i in range(len(self.target_data)) if i != loo_cand]\n",
    "        \n",
    "        a = Augmentor(filtered_inputs, filtered_targets)\n",
    "        a.generate_aug_data(20)\n",
    "        processed_inputs, processed_targets = model.assemble_data(a.aug_input_data, a.aug_label_data)\n",
    "\n",
    "        training_results = {}\n",
    "        for s in range(1, steps + 1):\n",
    "            model._raw_train(processed_inputs, processed_targets, batch_size, train_rate, epochs_per_step)\n",
    "            training_results[s * epochs_per_step] = model.compute_inference(self.input_data[loo_cand])\n",
    "        return training_results\n",
    "\n",
    "    loo_candidates = range(len(self.input_data))\n",
    "    p = mp.Pool(threads)\n",
    "    results = p.map(loo_x_validate, loo_candidates)\n",
    "    p.close()\n",
    "\n",
    "    processed_results = {}\n",
    "    for k in results[0].keys():\n",
    "        processed_results[k] = [r[k] for r in results]\n",
    "    self.loo_cross_validation_results = processed_results\n",
    "    return self.loo_cross_validation_results\n",
    "    \n",
    "Evaluator.loo_cross_validation = loo_cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = '0123456789abcdefghijklmnopqrstuvwxyz!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ €£'\n",
    "\n",
    "def preprocess_fn(s):\n",
    "    s = s.lower()\n",
    "    ret_s = ''\n",
    "    for c in s:\n",
    "        if c in alphabet:\n",
    "            ret_s += c\n",
    "        else:\n",
    "            ret_s += '#'\n",
    "    return ret_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_args = {\n",
    "    'alphabet': alphabet,\n",
    "    'window_size': 5,\n",
    "    'preprocess': preprocess_fn,\n",
    "    'window_shift': 1    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(model_args, input_data, label_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.loo_cross_validation(steps=15, epochs_per_step=2000)\n",
    "evaluator.compute_accuracy_curve(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_data = [\n",
    "    np.array([evaluator.accuracy_curve_results[k][i] for k in evaluator.accuracy_curve_results.keys()]).mean()\n",
    "    for i in range(len(evaluator.accuracy_curve_results[2000]))\n",
    "]\n",
    "stddev_data = [\n",
    "    np.array([evaluator.accuracy_curve_results[k][i] for k in evaluator.accuracy_curve_results.keys()]).std()\n",
    "    for i in range(len(evaluator.accuracy_curve_results[2000]))\n",
    "]\n",
    "max_data = [\n",
    "    np.array([evaluator.accuracy_curve_results[k][i] for k in evaluator.accuracy_curve_results.keys()]).max()\n",
    "    for i in range(len(evaluator.accuracy_curve_results[2000]))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import plotly.offline as plotly\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "fill": "tonexty",
         "fillcolor": "rgba(26,150,65,0.05)",
         "line": {
          "color": "rgba(26,150,65,0.1)",
          "shape": "spline",
          "smoothing": 1000
         },
         "mode": "lines",
         "name": "spread",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
         ]
        },
        {
         "line": {
          "color": "rgb(35,159,255)",
          "shape": "spline",
          "smoothing": 500
         },
         "mode": "lines",
         "name": "mean",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
         ]
        },
        {
         "line": {
          "color": "rgba(255,89,12, 0.3)",
          "shape": "spline",
          "smoothing": 500
         },
         "mode": "lines",
         "name": "max",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
         ]
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "rgba(0,0,0,0)",
         "font": {
          "color": "#727272",
          "family": "sans-serif",
          "size": 10
         },
         "x": 0.05,
         "y": 0.15
        },
        "title": {
         "text": "Accuracy During Training at Different Thresholds",
         "x": 0.1
        },
        "titlefont": {
         "color": "#727272",
         "family": "sans serif",
         "size": 14
        },
        "xaxis": {
         "range": [
          -1,
          101
         ],
         "title": "Threshold",
         "titlefont": {
          "color": "#727272",
          "family": "sans serif",
          "size": 10
         },
         "zeroline": false
        },
        "yaxis": {
         "title": "Accuracy",
         "titlefont": {
          "color": "#727272",
          "family": "sans serif",
          "size": 10
         },
         "zeroline": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frames = [\n",
    "    go.Scatter(\n",
    "        y=800*np.array(stddev_data)**3,\n",
    "        x=list(range(len(evaluator.accuracy_curve_results[2000]))),\n",
    "        mode='lines',\n",
    "        name='spread',\n",
    "        line={'smoothing': 1000, 'shape': 'spline','color':'rgba(26,150,65,0.1)'},\n",
    "        fillcolor='rgba(26,150,65,0.05)',\n",
    "        fill='tonexty',\n",
    "    ),\n",
    "    go.Scatter(\n",
    "        y=mean_data,\n",
    "        x=list(range(len(evaluator.accuracy_curve_results[2000]))),\n",
    "        mode='lines',\n",
    "        line={'smoothing': 500, 'shape': 'spline', 'color':'rgb(35,159,255)'},\n",
    "        name='mean',\n",
    "    ),\n",
    "    go.Scatter(\n",
    "        y=max_data,\n",
    "        x=list(range(len(evaluator.accuracy_curve_results[2000]))),\n",
    "        mode='lines',\n",
    "        line={'smoothing': 500, 'shape': 'spline', 'color':'rgba(255,89,12, 0.3)'},\n",
    "        name='max',\n",
    "    ),\n",
    "]\n",
    "layout = go.Layout(\n",
    "    title=dict(text='Accuracy During Training at Different Thresholds', x=0.1),\n",
    "    xaxis=dict(\n",
    "        range=[-1, 101], zeroline=False, title=\"Threshold\",\n",
    "        titlefont=dict(family='sans serif', size=10, color='#727272')),\n",
    "    yaxis=dict(\n",
    "        zeroline=False, title=\"Accuracy\",\n",
    "        titlefont=dict(family='sans serif', size=10, color='#727272')),\n",
    "    legend=dict(\n",
    "        x=0.05, y=0.15,\n",
    "        font=dict(family='sans-serif', size=10, color='#727272'),\n",
    "        bgcolor='rgba(0,0,0,0)'\n",
    "    ),\n",
    "    titlefont=dict(family='sans serif', size=14, color='#727272')\n",
    ")\n",
    "fig = go.Figure(data=frames, layout=layout)\n",
    "plotly.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///Users/frankwang/projects/data_model_repo/temp-plot.html'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plotly.plot(fig, image_filename='threshold_selection', image='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frames = [\n",
    "    go.Scatter(\n",
    "        y=[evaluator.accuracy_curve_results[k][i * 20] for k in evaluator.accuracy_curve_results.keys()],\n",
    "        x=np.array(range(len(evaluator.accuracy_curve_results[2000]))) * 2000,\n",
    "        mode='lines',\n",
    "        opacity=0.4,\n",
    "        line={'smoothing': 1000, 'shape': 'spline'},\n",
    "        name=\"{} threshhold\".format(i / 5)\n",
    "    )\n",
    "    for i in range(1, 5)\n",
    "]\n",
    "layout = go.Layout(\n",
    "    title=dict(text='Accuracy During Training at Different Thresholds', x=0.1),\n",
    "    xaxis=dict(\n",
    "        zeroline=False, title=\"Epochs\",\n",
    "        titlefont=dict(family='sans serif', size=10, color='#727272')),\n",
    "    yaxis=dict(\n",
    "        zeroline=False, title=\"Test Accuracy\",\n",
    "        titlefont=dict(family='sans serif', size=10, color='#727272')),\n",
    "    legend=dict(\n",
    "        x=0.05, y=0.15,\n",
    "        font=dict(family='sans-serif', size=10, color='#727272'),\n",
    "        bgcolor='rgba(0,0,0,0)'),\n",
    "    titlefont=dict(family='sans serif', size=14, color='#727272')\n",
    ")\n",
    "fig = go.Figure(data=frames, layout=layout)\n",
    "plotly.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotly_.plot(fig, image_filename='accuracy_epochs.svg', image='svg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
